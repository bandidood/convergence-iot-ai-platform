import { useState, useEffect, useRef, useCallback } from 'react';

interface UseSpeechSynthesisOptions {
  rate?: number;
  pitch?: number;
  volume?: number;
  lang?: string;
  voice?: SpeechSynthesisVoice | null;
}

interface SpeechQueueItem {
  id: string;
  text: string;
  options: UseSpeechSynthesisOptions;
  utterance: SpeechSynthesisUtterance;
}

export const useSpeechSynthesis = (options: UseSpeechSynthesisOptions = {}) => {
  const [isSupported, setIsSupported] = useState(false);
  const [speaking, setSpeaking] = useState(false);
  const [pending, setPending] = useState(false);
  const [paused, setPaused] = useState(false);
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
  const [selectedVoice, setSelectedVoice] = useState<SpeechSynthesisVoice | null>(null);
  const [currentText, setCurrentText] = useState('');
  const [error, setError] = useState<string | null>(null);

  const speechQueue = useRef<SpeechQueueItem[]>([]);
  const currentUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const isInitializedRef = useRef(false);

  const {
    rate = 1.0,
    pitch = 1.0,
    volume = 0.8,
    lang = 'fr-FR',
    voice = null,
  } = options;

  // VÃ©rification du support et initialisation
  useEffect(() => {
    if (typeof window === 'undefined' || !window.speechSynthesis) {
      setIsSupported(false);
      console.warn('ðŸ”Š Speech Synthesis API non supportÃ©e par ce navigateur');
      return;
    }

    setIsSupported(true);
    loadVoices();

    // Ã‰couter les changements de voix (certains navigateurs chargent les voix de faÃ§on asynchrone)
    const handleVoicesChanged = () => {
      loadVoices();
    };

    if (speechSynthesis.onvoiceschanged !== undefined) {
      speechSynthesis.onvoiceschanged = handleVoicesChanged;
    }

    // Nettoyage au dÃ©montage
    return () => {
      if (speechSynthesis.speaking) {
        speechSynthesis.cancel();
      }
      if (speechSynthesis.onvoiceschanged) {
        speechSynthesis.onvoiceschanged = null;
      }
    };
  }, []);

  // Chargement des voix disponibles
  const loadVoices = useCallback(() => {
    const availableVoices = speechSynthesis.getVoices();
    setVoices(availableVoices);

    // SÃ©lection automatique d'une voix franÃ§aise si disponible
    if (!selectedVoice && availableVoices.length > 0) {
      const frenchVoice = availableVoices.find(v => 
        v.lang.startsWith('fr') && v.default
      ) || availableVoices.find(v => v.lang.startsWith('fr')) || availableVoices[0];

      setSelectedVoice(frenchVoice);
      console.log('ðŸ”Š Voix sÃ©lectionnÃ©e:', frenchVoice?.name, frenchVoice?.lang);
    }

    if (!isInitializedRef.current && availableVoices.length > 0) {
      isInitializedRef.current = true;
      console.log('ðŸ”Š Speech Synthesis initialisÃ© avec', availableVoices.length, 'voix disponibles');
    }
  }, [selectedVoice]);

  // Fonction pour crÃ©er une utterance
  const createUtterance = useCallback((text: string, customOptions?: Partial<UseSpeechSynthesisOptions>) => {
    const utterance = new SpeechSynthesisUtterance(text);
    
    // Configuration des paramÃ¨tres
    utterance.rate = customOptions?.rate ?? rate;
    utterance.pitch = customOptions?.pitch ?? pitch;
    utterance.volume = customOptions?.volume ?? volume;
    utterance.lang = customOptions?.lang ?? lang;
    utterance.voice = customOptions?.voice ?? selectedVoice ?? voice;

    return utterance;
  }, [rate, pitch, volume, lang, selectedVoice, voice]);

  // Gestion des Ã©vÃ©nements utterance
  const setupUtteranceEvents = useCallback((
    utterance: SpeechSynthesisUtterance, 
    id: string,
    onComplete?: () => void
  ) => {
    utterance.onstart = () => {
      console.log('ðŸ”Š SynthÃ¨se vocale dÃ©marrÃ©e:', id);
      setSpeaking(true);
      setPending(false);
      setError(null);
    };

    utterance.onend = () => {
      console.log('ðŸ”Š SynthÃ¨se vocale terminÃ©e:', id);
      setSpeaking(false);
      setCurrentText('');
      currentUtteranceRef.current = null;
      
      // Traitement du prochain Ã©lÃ©ment dans la queue
      processQueue();
      onComplete?.();
    };

    utterance.onerror = (event) => {
      console.error('ðŸ”Š Erreur synthÃ¨se vocale:', event.error, event.name);
      setSpeaking(false);
      setPending(false);
      setError(`Erreur synthÃ¨se vocale: ${event.error}`);
      
      // Continuer avec le prochain Ã©lÃ©ment malgrÃ© l'erreur
      processQueue();
    };

    utterance.onpause = () => {
      console.log('ðŸ”Š SynthÃ¨se vocale en pause:', id);
      setPaused(true);
    };

    utterance.onresume = () => {
      console.log('ðŸ”Š SynthÃ¨se vocale reprise:', id);
      setPaused(false);
    };

    utterance.onboundary = (event) => {
      // Ã‰vÃ©nement dÃ©clenchÃ© Ã  chaque mot/phrase (optionnel pour feedback visuel)
      if (event.name === 'word') {
        const spokenText = utterance.text.substring(0, event.charIndex);
        // Peut Ãªtre utilisÃ© pour surligner le texte en cours de lecture
      }
    };
  }, []);

  // Traitement de la queue de synthÃ¨se
  const processQueue = useCallback(() => {
    if (speechQueue.current.length === 0 || speaking) {
      return;
    }

    const nextItem = speechQueue.current.shift();
    if (nextItem) {
      setCurrentText(nextItem.text);
      currentUtteranceRef.current = nextItem.utterance;
      speechSynthesis.speak(nextItem.utterance);
    }
  }, [speaking]);

  // Fonction principale pour parler
  const speak = useCallback((
    text: string, 
    customOptions?: Partial<UseSpeechSynthesisOptions>,
    priority: 'high' | 'normal' = 'normal'
  ): Promise<void> => {
    if (!isSupported || !text.trim()) {
      return Promise.resolve();
    }

    return new Promise((resolve, reject) => {
      try {
        const utterance = createUtterance(text, customOptions);
        const id = Date.now().toString();

        setupUtteranceEvents(utterance, id, () => resolve());

        const queueItem: SpeechQueueItem = {
          id,
          text: text.trim(),
          options: { ...options, ...customOptions },
          utterance,
        };

        // Gestion de la prioritÃ©
        if (priority === 'high') {
          // ArrÃªter la synthÃ¨se actuelle et placer en tÃªte de queue
          if (speaking) {
            speechSynthesis.cancel();
          }
          speechQueue.current.unshift(queueItem);
        } else {
          speechQueue.current.push(queueItem);
        }

        setPending(speechQueue.current.length > 0);
        
        // DÃ©marrer le traitement si pas de synthÃ¨se en cours
        if (!speaking) {
          processQueue();
        }

        console.log('ðŸ”Š AjoutÃ© Ã  la queue de synthÃ¨se:', { id, priority, queueLength: speechQueue.current.length });

      } catch (error: any) {
        console.error('ðŸ”Š Erreur crÃ©ation utterance:', error);
        setError(`Erreur crÃ©ation utterance: ${error.message}`);
        reject(error);
      }
    });
  }, [isSupported, createUtterance, setupUtteranceEvents, speaking, processQueue, options]);

  // ArrÃªter la synthÃ¨se
  const stop = useCallback(() => {
    if (!isSupported) return;

    speechSynthesis.cancel();
    speechQueue.current = [];
    setSpeaking(false);
    setPending(false);
    setPaused(false);
    setCurrentText('');
    currentUtteranceRef.current = null;
    
    console.log('ðŸ”Š SynthÃ¨se vocale arrÃªtÃ©e et queue vidÃ©e');
  }, [isSupported]);

  // Mettre en pause
  const pause = useCallback(() => {
    if (!isSupported || !speaking) return;

    speechSynthesis.pause();
    console.log('ðŸ”Š SynthÃ¨se vocale mise en pause');
  }, [isSupported, speaking]);

  // Reprendre
  const resume = useCallback(() => {
    if (!isSupported || !paused) return;

    speechSynthesis.resume();
    console.log('ðŸ”Š SynthÃ¨se vocale reprise');
  }, [isSupported, paused]);

  // SÃ©lectionner une voix
  const setVoice = useCallback((voice: SpeechSynthesisVoice) => {
    setSelectedVoice(voice);
    console.log('ðŸ”Š Voix changÃ©e:', voice.name, voice.lang);
  }, []);

  // Obtenir les voix filtrÃ©es par langue
  const getVoicesByLanguage = useCallback((language: string) => {
    return voices.filter(voice => voice.lang.startsWith(language));
  }, [voices]);

  // Obtenir la voix par dÃ©faut pour une langue
  const getDefaultVoiceForLanguage = useCallback((language: string) => {
    const languageVoices = getVoicesByLanguage(language);
    return languageVoices.find(voice => voice.default) || languageVoices[0] || null;
  }, [getVoicesByLanguage]);

  // Test de synthÃ¨se
  const testSpeech = useCallback(async (testText?: string) => {
    const text = testText || 'Test de synthÃ¨se vocale pour la Station TraffeyÃ¨re';
    try {
      await speak(text, { rate: 1.2, pitch: 1.0, volume: 0.6 });
      return true;
    } catch (error) {
      console.error('ðŸ”Š Erreur test synthÃ¨se:', error);
      return false;
    }
  }, [speak]);

  // Obtenir les capacitÃ©s de synthÃ¨se
  const getCapabilities = useCallback(() => {
    return {
      supported: isSupported,
      voicesCount: voices.length,
      selectedVoice: selectedVoice?.name || null,
      currentLanguage: selectedVoice?.lang || lang,
      supportedLanguages: [...new Set(voices.map(v => v.lang.split('-')[0]))],
      canPause: isSupported,
      canResume: isSupported,
      canCancel: isSupported,
    };
  }, [isSupported, voices, selectedVoice, lang]);

  // Parler des donnÃ©es IoT contextuelles
  const speakIoTData = useCallback(async (sensors: any[], anomalies: number) => {
    const activeSensors = sensors?.filter(s => s.status === 'online').length || 0;
    const totalSensors = sensors?.length || 0;
    
    let message = `Ã‰tat de la station TraffeyÃ¨re: ${activeSensors} capteurs actifs sur ${totalSensors}.`;
    
    if (anomalies > 0) {
      message += ` Attention: ${anomalies} anomalie${anomalies > 1 ? 's dÃ©tectÃ©es' : ' dÃ©tectÃ©e'}.`;
    } else {
      message += ' Tous les systÃ¨mes fonctionnent normalement.';
    }

    await speak(message, { rate: 1.1, pitch: 1.1 });
  }, [speak]);

  // Annoncer une alerte
  const announceAlert = useCallback(async (alertMessage: string, severity: 'low' | 'medium' | 'high' = 'medium') => {
    const prefixes = {
      low: 'Information',
      medium: 'Attention',
      high: 'Alerte critique',
    };

    const rates = {
      low: 1.0,
      medium: 0.9,
      high: 0.8,
    };

    const pitches = {
      low: 1.0,
      medium: 1.2,
      high: 1.4,
    };

    const message = `${prefixes[severity]}: ${alertMessage}`;
    
    await speak(message, {
      rate: rates[severity],
      pitch: pitches[severity],
      volume: 0.9,
    }, severity === 'high' ? 'high' : 'normal');
  }, [speak]);

  return {
    // Ã‰tat principal
    isSupported,
    speaking,
    pending,
    paused,
    voices,
    selectedVoice,
    currentText,
    error,

    // Actions principales
    speak,
    stop,
    pause,
    resume,
    setVoice,

    // Utilitaires
    getVoicesByLanguage,
    getDefaultVoiceForLanguage,
    testSpeech,
    getCapabilities,
    speakIoTData,
    announceAlert,

    // Configuration actuelle
    config: {
      rate,
      pitch,
      volume,
      lang,
      voice: selectedVoice,
    },

    // Informations sur la queue
    queueInfo: {
      length: speechQueue.current.length,
      isEmpty: speechQueue.current.length === 0,
      currentIndex: currentUtteranceRef.current ? 0 : -1,
    },
  };
};

export default useSpeechSynthesis;