import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  Box,
  Paper,
  Typography,
  IconButton,
  TextField,
  List,
  ListItem,
  ListItemText,
  ListItemAvatar,
  Avatar,
  Chip,
  Alert,
  CircularProgress,
  InputAdornment,
  Fade,
} from '@mui/material';
import {
  Send as SendIcon,
  Mic as MicIcon,
  MicOff as MicOffIcon,
  VolumeUp as VolumeUpIcon,
  SmartToy as SmartToyIcon,
  Person as PersonIcon,
  Clear as ClearIcon,
} from '@mui/icons-material';
import { motion, AnimatePresence } from 'framer-motion';

interface Message {
  id: string;
  text: string;
  sender: 'user' | 'ai';
  timestamp: Date;
}

interface ConversationalInterfaceProps {
  aiHook: any;
  voiceRecognition: any;
  speechSynthesis: any;
  websocket: any;
  config: any;
  theme: any;
  onAction: (action: string, data?: any) => void;
  sensorData: any[];
  alerts: any[];
  anomalies: number;
}

const ConversationalInterface: React.FC<ConversationalInterfaceProps> = ({
  aiHook,
  voiceRecognition,
  speechSynthesis,
  websocket,
  config,
  theme,
  onAction,
  sensorData,
  alerts,
  anomalies,
}) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Message d'accueil initial
  useEffect(() => {
    if (messages.length === 0) {
      const welcomeMessage: Message = {
        id: 'welcome',
        text: `Bonjour ! Je suis XIA, votre assistant IA pour la Station Traffey√®re. Je peux vous aider √† analyser les donn√©es de vos ${sensorData.length} capteurs IoT, expliquer les anomalies d√©tect√©es, et r√©pondre √† vos questions sur le syst√®me.`,
        sender: 'ai',
        timestamp: new Date(),
      };
      setMessages([welcomeMessage]);

      // Annonce vocale si disponible
      if (speechSynthesis.isSupported && config.iot.alertNotifications) {
        speechSynthesis.speak('Assistant XIA pr√™t pour la Station Traffey√®re');
      }
    }
  }, [messages.length, sensorData.length, speechSynthesis, config]);

  // Auto-scroll vers le bas
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // Gestion de l'envoi de message
  const handleSendMessage = useCallback(async () => {
    if (!inputText.trim() || isLoading) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      text: inputText,
      sender: 'user',
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsLoading(true);

    try {
      // Cr√©ation du contexte enrichi avec donn√©es IoT
      const context = {
        currentSensors: sensorData.length,
        activeSensors: sensorData.filter(s => s.status === 'online').length,
        anomalies,
        alerts: alerts.length,
        timestamp: new Date().toISOString(),
      };

      // Simulation de r√©ponse IA (√† remplacer par aiHook r√©el)
      await new Promise(resolve => setTimeout(resolve, 1500)); // Simulation latence

      let responseText = '';
      
      // R√©ponses contextuelles simples
      if (inputText.toLowerCase().includes('capteur') || inputText.toLowerCase().includes('sensor')) {
        responseText = `üìä Actuellement, ${context.activeSensors}/${context.currentSensors} capteurs sont en ligne. ${anomalies > 0 ? `‚ö†Ô∏è ${anomalies} anomalie(s) d√©tect√©e(s).` : '‚úÖ Tous les syst√®mes fonctionnent normalement.'}`;
      } else if (inputText.toLowerCase().includes('anomalie') || inputText.toLowerCase().includes('alerte')) {
        responseText = anomalies > 0 
          ? `üö® J'ai d√©tect√© ${anomalies} anomalie(s) sur la station. Les capteurs concern√©s n√©cessitent votre attention. Souhaitez-vous que j'analyse les d√©tails ?`
          : '‚úÖ Aucune anomalie d√©tect√©e actuellement. Tous les capteurs fonctionnent dans les param√®tres normaux.';
      } else if (inputText.toLowerCase().includes('temperature') || inputText.toLowerCase().includes('temp√©rature')) {
        const tempSensors = sensorData.filter(s => s.type === 'temperature');
        responseText = `üå°Ô∏è ${tempSensors.length} capteurs de temp√©rature actifs. La temp√©rature moyenne est stable.`;
      } else if (inputText.toLowerCase().includes('aide') || inputText.toLowerCase().includes('help')) {
        responseText = `üîß Je peux vous aider avec :
        ‚Ä¢ √âtat des capteurs IoT
        ‚Ä¢ Analyse des anomalies 
        ‚Ä¢ Explications des alertes
        ‚Ä¢ Navigation dans l'interface
        ‚Ä¢ Donn√©es temps r√©el
        
        Que souhaitez-vous savoir ?`;
      } else {
        responseText = `ü§ñ J'ai bien re√ßu votre message : "${inputText}". En tant qu'assistant IA de la Station Traffey√®re, je peux analyser vos donn√©es IoT et vous aider avec le syst√®me. Pouvez-vous pr√©ciser ce dont vous avez besoin ?`;
      }

      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        text: responseText,
        sender: 'ai',
        timestamp: new Date(),
      };

      setMessages(prev => [...prev, aiMessage]);

      // Synth√®se vocale si activ√©e
      if (speechSynthesis.isSupported && config.voice.enabled) {
        await speechSynthesis.speak(responseText);
      }

    } catch (error) {
      console.error('Erreur envoi message:', error);
      const errorMessage: Message = {
        id: (Date.now() + 2).toString(),
        text: 'D√©sol√©, une erreur est survenue. Veuillez r√©essayer.',
        sender: 'ai',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  }, [inputText, isLoading, sensorData, anomalies, alerts.length, speechSynthesis, config]);

  // Gestion du micro
  const handleMicToggle = useCallback(() => {
    if (voiceRecognition.listening) {
      voiceRecognition.stop();
    } else {
      voiceRecognition.start();
    }
  }, [voiceRecognition]);

  // Traitement transcript vocal
  useEffect(() => {
    if (voiceRecognition.finalTranscript) {
      setInputText(voiceRecognition.finalTranscript);
    }
  }, [voiceRecognition.finalTranscript]);

  // Effacer la conversation
  const handleClearConversation = () => {
    setMessages([]);
    onAction('clear-conversation');
  };

  return (
    <Box sx={{ height: '100%', display: 'flex', flexDirection: 'column' }}>
      {/* Zone de messages */}
      <Box sx={{ flex: 1, overflow: 'auto', p: 2 }}>
        <List>
          <AnimatePresence>
            {messages.map((message) => (
              <motion.div
                key={message.id}
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: -20 }}
                transition={{ duration: 0.3 }}
              >
                <ListItem 
                  sx={{ 
                    justifyContent: message.sender === 'user' ? 'flex-end' : 'flex-start',
                    mb: 1
                  }}
                >
                  <Paper
                    elevation={2}
                    sx={{
                      p: 2,
                      maxWidth: '75%',
                      bgcolor: message.sender === 'user' 
                        ? theme.messageUser 
                        : theme.messageAI,
                      color: 'white',
                      borderRadius: 3,
                      ...(message.sender === 'user' && {
                        borderBottomRightRadius: 8,
                      }),
                      ...(message.sender === 'ai' && {
                        borderBottomLeftRadius: 8,
                      }),
                    }}
                  >
                    <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mb: 1 }}>
                      <Avatar 
                        sx={{ 
                          width: 24, 
                          height: 24, 
                          bgcolor: 'rgba(255,255,255,0.2)' 
                        }}
                      >
                        {message.sender === 'user' ? (
                          <PersonIcon sx={{ fontSize: 16 }} />
                        ) : (
                          <SmartToyIcon sx={{ fontSize: 16 }} />
                        )}
                      </Avatar>
                      <Typography variant="caption" sx={{ opacity: 0.8 }}>
                        {message.timestamp.toLocaleTimeString()}
                      </Typography>
                    </Box>
                    
                    <Typography variant="body1" sx={{ whiteSpace: 'pre-wrap' }}>
                      {message.text}
                    </Typography>
                  </Paper>
                </ListItem>
              </motion.div>
            ))}
          </AnimatePresence>
        </List>
        
        {/* Indicateur de saisie */}
        {isLoading && (
          <Fade in={isLoading}>
            <Box sx={{ display: 'flex', alignItems: 'center', gap: 2, p: 2 }}>
              <CircularProgress size={20} />
              <Typography variant="body2" color="text.secondary">
                XIA r√©fl√©chit...
              </Typography>
            </Box>
          </Fade>
        )}
        
        <div ref={messagesEndRef} />
      </Box>

      {/* Zone de saisie */}
      <Paper 
        elevation={3} 
        sx={{ 
          p: 2, 
          m: 2, 
          bgcolor: 'rgba(255,255,255,0.95)',
          backdropFilter: 'blur(10px)',
        }}
      >
        {/* Transcript vocal en cours */}
        {voiceRecognition.listening && voiceRecognition.transcript && (
          <Alert severity="info" sx={{ mb: 2 }}>
            <Typography variant="body2">
              üé§ "{voiceRecognition.transcript}"
            </Typography>
          </Alert>
        )}

        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          {/* Bouton micro */}
          <IconButton
            onClick={handleMicToggle}
            color={voiceRecognition.listening ? 'primary' : 'default'}
            disabled={!voiceRecognition.isSupported}
          >
            {voiceRecognition.listening ? <MicIcon /> : <MicOffIcon />}
          </IconButton>

          {/* Champ de saisie */}
          <TextField
            fullWidth
            variant="outlined"
            size="small"
            placeholder="Tapez votre message ou utilisez le micro..."
            value={inputText}
            onChange={(e) => setInputText(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
            disabled={isLoading || voiceRecognition.listening}
            InputProps={{
              endAdornment: (
                <InputAdornment position="end">
                  <IconButton
                    onClick={handleSendMessage}
                    disabled={!inputText.trim() || isLoading}
                    color="primary"
                  >
                    <SendIcon />
                  </IconButton>
                </InputAdornment>
              ),
            }}
          />

          {/* Contr√¥les additionnels */}
          <Box sx={{ display: 'flex', gap: 0.5 }}>
            <IconButton
              size="small"
              onClick={() => speechSynthesis.stop()}
              disabled={!speechSynthesis.speaking}
              title="Arr√™ter la synth√®se"
            >
              <VolumeUpIcon />
            </IconButton>

            <IconButton
              size="small"
              onClick={handleClearConversation}
              title="Effacer la conversation"
            >
              <ClearIcon />
            </IconButton>
          </Box>
        </Box>

        {/* Informations contextuelles */}
        <Box sx={{ display: 'flex', gap: 1, mt: 1, flexWrap: 'wrap' }}>
          <Chip 
            size="small" 
            label={`${sensorData.length} capteurs`} 
            color="primary" 
            variant="outlined" 
          />
          {anomalies > 0 && (
            <Chip 
              size="small" 
              label={`${anomalies} anomalie(s)`} 
              color="error" 
              variant="outlined" 
            />
          )}
          {websocket.isConnected && (
            <Chip 
              size="small" 
              label="Temps r√©el" 
              color="success" 
              variant="outlined" 
            />
          )}
        </Box>
      </Paper>
    </Box>
  );
};

export default ConversationalInterface;