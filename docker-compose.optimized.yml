version: '3.8'

# ============================================================================
# DOCKER COMPOSE OPTIMIZED - Station Traffeyère IoT/AI Platform
# Architecture optimisée pour ressources et performance - RNCP 39394
# Optimisations: ressources, healthchecks, dépendances, sécurité
# ============================================================================

x-common-healthcheck: &common-healthcheck
  interval: 45s
  timeout: 10s
  retries: 3
  start_period: 60s

x-resource-limits: &resource-limits-small
  cpus: '0.5'
  memory: 512M

x-resource-limits-medium: &resource-limits-medium
  cpus: '1.0'
  memory: 1G

x-resource-limits-large: &resource-limits-large
  cpus: '2.0'
  memory: 2G

services:
  # Base de données principale avec optimisations
  postgres:
    image: timescale/timescaledb:2.11.2-pg15
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-station_traffeyere}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
      # Optimisations PostgreSQL
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-large
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-station_traffeyere}"]
      <<: *common-healthcheck
    sysctls:
      - net.core.somaxconn=65535

  # Cache Redis optimisé
  redis:
    image: redis:7.2-alpine
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-small
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s

  # InfluxDB avec cache optimisé
  influxdb:
    image: influxdb:2.7-alpine
    restart: unless-stopped
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUX_USERNAME:-admin}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUX_PASSWORD}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUX_ORG:-traffeyere}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUX_BUCKET:-iot_sensors}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUX_ADMIN_TOKEN}
      # Optimisations InfluxDB
      INFLUXD_QUERY_CACHE_MAX_MEMORY_SIZE: 134217728
      INFLUXD_QUERY_QUEUE_SIZE: 20
    volumes:
      - influxdb_data:/var/lib/influxdb2
      - influxdb_config:/etc/influxdb2
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "-qO-", "--timeout=5", "http://localhost:8086/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.influxdb.rule=Host(`influx.johann-lebel.fr`)"
      - "traefik.http.routers.influxdb.tls=true"
      - "traefik.http.routers.influxdb.tls.certresolver=letsencrypt"
      - "traefik.http.services.influxdb.loadbalancer.server.port=8086"

  # MinIO avec optimisations stockage
  minio:
    image: minio/minio:RELEASE.2024-01-01T16-36-33Z
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_CONSOLE_ADDRESS: ":9090"
      # Optimisations MinIO
      MINIO_CACHE_DRIVES: "/cache"
      MINIO_CACHE_QUOTA: 80
    command: server /data --console-address ":9090"
    volumes:
      - minio_data:/data
      - minio_cache:/cache
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.minio-api.rule=Host(`minio.johann-lebel.fr`)"
      - "traefik.http.routers.minio-api.tls=true"
      - "traefik.http.routers.minio-api.tls.certresolver=letsencrypt"
      - "traefik.http.services.minio-api.loadbalancer.server.port=9000"
      - "traefik.http.routers.minio-console.rule=Host(`minio-console.johann-lebel.fr`)"
      - "traefik.http.routers.minio-console.tls=true"
      - "traefik.http.routers.minio-console.tls.certresolver=letsencrypt"
      - "traefik.http.services.minio-console.loadbalancer.server.port=9090"

  # Keycloak avec base dédiée
  keycloak-db:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: ${KEYCLOAK_DB_PASSWORD}
    volumes:
      - keycloak_db_data:/var/lib/postgresql/data
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-small
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U keycloak -d keycloak"]
      <<: *common-healthcheck

  keycloak:
    image: quay.io/keycloak/keycloak:23.0.1
    restart: unless-stopped
    environment:
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN_USER:-admin}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}
      KC_DB: postgres
      KC_DB_URL_HOST: keycloak-db
      KC_DB_URL_DATABASE: keycloak
      KC_DB_USERNAME: keycloak
      KC_DB_PASSWORD: ${KEYCLOAK_DB_PASSWORD}
      KC_HOSTNAME: auth.johann-lebel.fr
      KC_HTTP_ENABLED: true
      KC_PROXY: edge
      # Optimisations Keycloak
      JAVA_OPTS_APPEND: "-XX:MaxRAMPercentage=50.0 -XX:+UseG1GC"
    command:
      - start
      - --auto-build
      - --db=postgres
      - --db-pool-initial-size=5
      - --db-pool-max-size=10
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - backend
      - frontend
    depends_on:
      keycloak-db:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "curl -f --max-time 10 http://localhost:8080/health/ready || exit 1"]
      interval: 90s
      timeout: 20s
      retries: 5
      start_period: 180s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.keycloak.rule=Host(`auth.johann-lebel.fr`)"
      - "traefik.http.routers.keycloak.tls=true"
      - "traefik.http.routers.keycloak.tls.certresolver=letsencrypt"
      - "traefik.http.services.keycloak.loadbalancer.server.port=8080"

  # Prometheus avec rétention optimisée
  prometheus:
    image: prom/prometheus:v2.47.2
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=8GB'
      - '--query.max-concurrency=4'
      - '--query.max-samples=50000000'
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "-qO-", "--timeout=3", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 8s
      retries: 3
      start_period: 45s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`metrics.johann-lebel.fr`)"
      - "traefik.http.routers.prometheus.tls=true"
      - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"

  # Grafana avec base dédiée et optimisations
  grafana-db:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: grafana
      POSTGRES_USER: grafana
      POSTGRES_PASSWORD: ${GRAFANA_DB_PASSWORD}
    volumes:
      - grafana_db_data:/var/lib/postgresql/data
    networks:
      - backend
    deploy:
      resources:
        limits:
          <<: *resource-limits-small
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U grafana -d grafana"]
      <<: *common-healthcheck

  grafana:
    image: grafana/grafana:10.2.0
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: grafana-db:5432
      GF_DATABASE_NAME: grafana
      GF_DATABASE_USER: grafana
      GF_DATABASE_PASSWORD: ${GRAFANA_DB_PASSWORD}
      GF_SERVER_DOMAIN: grafana.johann-lebel.fr
      GF_SERVER_ROOT_URL: https://grafana.johann-lebel.fr
      # Optimisations Grafana
      GF_RENDERING_SERVER_URL: http://grafana-renderer:8081/render
      GF_RENDERING_CALLBACK_URL: http://grafana:3000/
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - backend
      - frontend
    depends_on:
      grafana-db:
        condition: service_healthy
      prometheus:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "curl -f --max-time 3 http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 8s
      retries: 3
      start_period: 90s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.johann-lebel.fr`)"
      - "traefik.http.routers.grafana.tls=true"
      - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"

  # MQTT avec persistance optimisée
  mosquitto:
    image: eclipse-mosquitto:2.0.18
    restart: unless-stopped
    volumes:
      - mosquitto_data:/mosquitto/data
      - mosquitto_logs:/mosquitto/log
      - ./config/mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf:ro
    networks:
      - backend
      - iot_network
    deploy:
      resources:
        limits:
          <<: *resource-limits-small
    healthcheck:
      test: ["CMD", "sh", "-c", "timeout 5 mosquitto_pub -h localhost -p 1883 -t test/health -m ping"]
      <<: *common-healthcheck
    labels:
      - "traefik.enable=true"
      - "traefik.tcp.routers.mqtt.rule=HostSNI(`*`)"
      - "traefik.tcp.routers.mqtt.entrypoints=mqtt"
      - "traefik.tcp.services.mqtt.loadbalancer.server.port=1883"

  # Edge AI Engine optimisé
  edge-ai:
    build:
      context: .
      dockerfile: ./core/edge-ai-engine/Dockerfile.simple
      cache_from:
        - edge-ai:cache
    restart: unless-stopped
    environment:
      EDGE_AI_MODEL_PATH: /app/models
      EDGE_AI_INFERENCE_TIMEOUT: 1
      ANOMALY_THRESHOLD: 0.85
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      INFLUX_URL: http://influxdb:8086
      INFLUX_TOKEN: ${INFLUX_ADMIN_TOKEN}
      MQTT_BROKER_HOST: mosquitto
      MQTT_BROKER_PORT: 1883
      # Optimisations IA
      PYTHONUNBUFFERED: 1
      OMP_NUM_THREADS: 2
      CUDA_VISIBLE_DEVICES: ""
    volumes:
      - edge_ai_models:/app/models:cached
      - edge_ai_cache:/app/cache
    networks:
      - backend
      - iot_network
    depends_on:
      redis:
        condition: service_healthy
      influxdb:
        condition: service_healthy
      mosquitto:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8001/health"]
      interval: 90s
      timeout: 20s
      retries: 5
      start_period: 120s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.edge-ai.rule=Host(`edge-ai.johann-lebel.fr`)"
      - "traefik.http.routers.edge-ai.tls=true"
      - "traefik.http.routers.edge-ai.tls.certresolver=letsencrypt"
      - "traefik.http.services.edge-ai.loadbalancer.server.port=8001"

  # Backend optimisé avec build cache
  backend:
    build:
      context: .
      dockerfile: ./services/backend/Dockerfile
      cache_from:
        - backend:cache
      args:
        - ENVIRONMENT=production
        - BUILDKIT_INLINE_CACHE=1
    restart: unless-stopped
    environment:
      PROJECT_NAME: "Station Traffeyère IoT/AI Platform"
      RNCP_CODE: "39394"
      ENVIRONMENT: production
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-station_traffeyere}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      INFLUX_URL: http://influxdb:8086
      INFLUX_TOKEN: ${INFLUX_ADMIN_TOKEN}
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_ROOT_USER}
      S3_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      SECRET_KEY: ${SECRET_KEY}
      JWT_SECRET: ${JWT_SECRET}
      KEYCLOAK_URL: http://keycloak:8080/auth
      MQTT_BROKER_HOST: mosquitto
      MQTT_BROKER_PORT: 1883
      STATION_ID: ${STATION_ID:-TRAFFEYERE_001}
      AI_MODEL_PATH: /app/models
      # Optimisations FastAPI
      WORKERS: 2
      MAX_WORKERS: 4
      PYTHONUNBUFFERED: 1
    volumes:
      - backend_logs:/app/logs
      - backend_models:/app/models:cached
    networks:
      - backend
      - frontend
      - iot_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8000/health"]
      <<: *common-healthcheck
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`backend-station.johann-lebel.fr`) || Host(`api.johann-lebel.fr`)"
      - "traefik.http.routers.backend.tls=true"
      - "traefik.http.routers.backend.tls.certresolver=letsencrypt"
      - "traefik.http.services.backend.loadbalancer.server.port=8000"

  # Frontend avec build cache
  frontend:
    build:
      context: .
      dockerfile: ./services/frontend/Dockerfile
      cache_from:
        - frontend:cache
      args:
        - VITE_API_URL=https://backend-station.johann-lebel.fr
        - VITE_WS_URL=wss://backend-station.johann-lebel.fr/ws
        - VITE_GRAFANA_URL=https://grafana.johann-lebel.fr
        - VITE_XAI_URL=https://xai.johann-lebel.fr
        - VITE_KEYCLOAK_URL=https://auth.johann-lebel.fr
        - VITE_KEYCLOAK_REALM=traffeyere
        - VITE_ENVIRONMENT=production
        - BUILDKIT_INLINE_CACHE=1
    restart: unless-stopped
    networks:
      - frontend
    deploy:
      resources:
        limits:
          <<: *resource-limits-small
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "3", "http://localhost/healthz"]
      <<: *common-healthcheck
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`frontend-station.johann-lebel.fr`) || Host(`traffeyere.johann-lebel.fr`)"
      - "traefik.http.routers.frontend.tls=true"
      - "traefik.http.routers.frontend.tls.certresolver=letsencrypt"
      - "traefik.http.services.frontend.loadbalancer.server.port=80"

  # Elasticsearch SIEM optimisé
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms768m -Xmx768m"
      - cluster.name=traffeyere-siem
      - bootstrap.memory_lock=false
      - indices.fielddata.cache.size=30%
      - indices.queries.cache.size=10%
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.75'
          memory: 768M
    healthcheck:
      test: ["CMD-SHELL", "curl -f --max-time 10 http://localhost:9200/_cluster/health || exit 1"]
      interval: 120s
      timeout: 30s
      retries: 10
      start_period: 300s
    ulimits:
      memlock:
        soft: -1
        hard: -1

  # Kibana optimisé
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    restart: unless-stopped
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      SERVER_NAME: siem.johann-lebel.fr
      XPACK_SECURITY_ENABLED: false
      # Optimisations Kibana
      NODE_OPTIONS: "--max-old-space-size=512"
    volumes:
      - kibana_data:/usr/share/kibana/data
    networks:
      - backend
      - frontend
    depends_on:
      elasticsearch:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "curl -f --max-time 10 http://localhost:5601/api/status || exit 1"]
      interval: 120s
      timeout: 30s
      retries: 8
      start_period: 240s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.kibana.rule=Host(`siem.johann-lebel.fr`)"
      - "traefik.http.routers.kibana.tls=true"
      - "traefik.http.routers.kibana.tls.certresolver=letsencrypt"
      - "traefik.http.services.kibana.loadbalancer.server.port=5601"

  # XAI Dashboard optimisé
  xai-dashboard:
    build:
      context: .
      dockerfile: ./interfaces/voice-assistant-xia/Dockerfile.backend
      cache_from:
        - xai-dashboard:cache
    restart: unless-stopped
    environment:
      XAI_PORT: 8092
      MQTT_BROKER_HOST: mosquitto
      MQTT_BROKER_PORT: 1883
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      EDGE_AI_API_URL: http://edge-ai:8001
      SHAP_ENABLED: true
      STATION_ID: ${STATION_ID:-TRAFFEYERE_001}
      # Optimisations XAI
      PYTHONUNBUFFERED: 1
      OMP_NUM_THREADS: 2
    volumes:
      - xai_logs:/app/logs
      - xai_models:/app/models:cached
    networks:
      - backend
      - frontend
    depends_on:
      redis:
        condition: service_healthy
      edge-ai:
        condition: service_healthy
    deploy:
      resources:
        limits:
          <<: *resource-limits-medium
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8092/health"]
      interval: 90s
      timeout: 20s
      retries: 5
      start_period: 150s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.xai.rule=Host(`xai.johann-lebel.fr`)"
      - "traefik.http.routers.xai.tls=true"
      - "traefik.http.routers.xai.tls.certresolver=letsencrypt"
      - "traefik.http.services.xai.loadbalancer.server.port=8092"

# Volumes persistants optimisés
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/postgres
  keycloak_db_data:
    driver: local
  grafana_db_data:
    driver: local
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis
  influxdb_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/influxdb
  influxdb_config:
    driver: local
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/minio
  minio_cache:
    driver: local
  keycloak_data:
    driver: local
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/grafana
  mosquitto_data:
    driver: local
  mosquitto_logs:
    driver: local
  edge_ai_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models/edge-ai
  edge_ai_cache:
    driver: local
  backend_logs:
    driver: local
  backend_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models/backend
  elasticsearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/elasticsearch
  kibana_data:
    driver: local
  xai_logs:
    driver: local
  xai_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models/xai

# Réseaux segmentés simplifiés pour éviter les conflits
networks:
  backend:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500
  frontend:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500
  iot_network:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500